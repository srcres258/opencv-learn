{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Image Read\n",
    "\n",
    "- cv2.IMREAD_COLOR: colorful image\n",
    "- cv2.IMREAD_GRAYSTYLE: gray image"
   ],
   "id": "a41224edd2e534fe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import cv2 # Note that color format of OpenCV is BGR here.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "img = cv2.imread('test1.jpg')"
   ],
   "id": "c7300c1977d7ddf8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "img",
   "id": "afd3397c68b7423c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Display the image. Multiple windows can be created as well.\n",
    "cv2.imshow('image',img)\n",
    "# Wait for some time (in milliseconds). 0 means wait for any key input.\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "3f4f7ce969768f3e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def cv_show(name, img):\n",
    "    cv2.imshow(name, img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ],
   "id": "73b0c9779454ca20",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "img.shape",
   "id": "5c96c5c6060b581e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "img = cv2.imread('test1.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "img"
   ],
   "id": "e4eda804b61d82a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "img.shape",
   "id": "9d63011b1937ebe7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Display the image. Multiple windows can be created as well.\n",
    "cv2.imshow('image',img)\n",
    "# Wait for some time (in milliseconds). 0 means wait for any key input.\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "5818200bc13521a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Save\n",
    "if not os.path.exists('run'):\n",
    "    os.mkdir('run')\n",
    "cv2.imwrite('run/myimg.jpg',img)"
   ],
   "id": "fb602c6eae996227",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "type(img)",
   "id": "81caf306dd9bbd35",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "img.size",
   "id": "896f658e8039343d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "img.dtype",
   "id": "8947134d500b3f3f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Video Read\n",
    "\n",
    "- cv2.VideoCapture can be used to capture video contents from cameras. Use numbers to control different devices, e.g. 0 or 1.\n",
    "- If video file is needed, just specify the path."
   ],
   "id": "b97709b1ad64d08b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "vc = cv2.VideoCapture('test.mp4')",
   "id": "a9874fe535c403b8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check if it's correctly opened.\n",
    "if vc.isOpened():\n",
    "    open_, frame = vc.read()\n",
    "else:\n",
    "    open_ = False"
   ],
   "id": "41565c6348513156",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "while open_:\n",
    "    ret, frame = vc.read()\n",
    "    if frame is None:\n",
    "        break\n",
    "    if ret:\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        cv2.imshow('frame', gray)\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "vc.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "d623b646f81f3ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Cut out some image data",
   "id": "73c706999d1dec7b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "img = cv2.imread('test1.jpg')\n",
    "cat = img[0:100, 0:100]\n",
    "cv_show('cat', cat)"
   ],
   "id": "f36654d956be8fdf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Color channel extract",
   "id": "4723be0a9eac7e06"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "b, g, r = cv2.split(img)",
   "id": "e9e3ecc1a8ff1035",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "b",
   "id": "ccff2c085e7a6f2e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "b.shape",
   "id": "801282d8c5997475",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "img = cv2.merge((b, g, r))\n",
    "img.shape"
   ],
   "id": "afcdc7988553e30b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Only reserve R\n",
    "cur_img = img.copy()\n",
    "cur_img[:, :, 0] = 0\n",
    "cur_img[:, :, 1] = 0\n",
    "cv_show('R', cur_img)"
   ],
   "id": "37c3baa6b94e6f06",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Only reserve G\n",
    "cur_img = img.copy()\n",
    "cur_img[:, :, 0] = 0\n",
    "cur_img[:, :, 2] = 0\n",
    "cv_show('G', cur_img)"
   ],
   "id": "c46a57a6a1e06f78",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Only reserve B\n",
    "cur_img = img.copy()\n",
    "cur_img[:, :, 1] = 0\n",
    "cur_img[:, :, 2] = 0\n",
    "cv_show('B', cur_img)"
   ],
   "id": "7f35279626b567d4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Border filling",
   "id": "4fa9cde068e0bd91"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "top_size, bottom_size, left_size, right_size = (50, 50, 50, 50)\n",
    "\n",
    "replicate = cv2.copyMakeBorder(img, top_size, bottom_size, left_size, right_size, borderType=cv2.BORDER_REPLICATE)\n",
    "reflect = cv2.copyMakeBorder(img, top_size, bottom_size, left_size, right_size, borderType=cv2.BORDER_REFLECT)\n",
    "reflect101 = cv2.copyMakeBorder(img, top_size, bottom_size, left_size, right_size, borderType=cv2.BORDER_REFLECT_101)\n",
    "wrap = cv2.copyMakeBorder(img, top_size, bottom_size, left_size, right_size, borderType=cv2.BORDER_WRAP)\n",
    "constant = cv2.copyMakeBorder(img, top_size, bottom_size, left_size, right_size, borderType=cv2.BORDER_CONSTANT, value=0)"
   ],
   "id": "2df3ba53ed00875c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.subplot(231), plt.imshow(img, 'gray'), plt.title('Original')\n",
    "plt.subplot(232), plt.imshow(replicate, 'gray'), plt.title('Replicate')\n",
    "plt.subplot(233), plt.imshow(reflect, 'gray'), plt.title('Reflect')\n",
    "plt.subplot(234), plt.imshow(reflect101, 'gray'), plt.title('Reflect101')\n",
    "plt.subplot(235), plt.imshow(wrap, 'gray'), plt.title('Wrap')\n",
    "plt.subplot(236), plt.imshow(constant, 'gray'), plt.title('Constant')\n",
    "\n",
    "plt.show()"
   ],
   "id": "8eba0d321a1e238a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- BORDER_REPLICATE\n",
    "- BORDER_REFLECT: fedcba|abcdefgh|hgfedcb\n",
    "- BORDER_REFLECT_101: gfedcb|abcdefgh|gfedcba\n",
    "- BORDER_WRAP: cdefgh|abcdefgh|abcdefg\n",
    "- BORDER_CONSTANT"
   ],
   "id": "32fc4ec2a45c7bc1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Value calculating",
   "id": "45124a739b8bd1cc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "img1 = cv2.imread('test1.jpg')\n",
    "img2 = cv2.imread('test2.jpg')"
   ],
   "id": "97f223c7bfd6312b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "img1_1 = img1 + 10\n",
    "img1[:5, :, 0]"
   ],
   "id": "81e5a61ce3996b84",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "img1_1[:5, :, 0]",
   "id": "8b26dad0b70b25b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# equivalent to `% 256`\n",
    "(img1 + img1_1)[:5, :, 0]"
   ],
   "id": "972d93918666d9ba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "cv2.add(img1, img1_1)[:5, :, 0]",
   "id": "549746fd489780d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Image blending",
   "id": "a762a3d30f72e564"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "img1 + img2",
   "id": "2581cf6a9bda4e73",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "img1.shape",
   "id": "79603668bc16cc56",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "img2 = cv2.resize(img2, (300, 300))\n",
    "img2.shape"
   ],
   "id": "2d7dd1c653440b57",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "res = cv2.addWeighted(img1, 0.4, img2, 0.6, 0)",
   "id": "653a6c796cf64c38",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plt.imshow(res)",
   "id": "6507205ef98734e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "res = cv2.resize(img1, (0, 0), fx=3, fy=1)\n",
    "plt.imshow(res)"
   ],
   "id": "366435f78e47bcb4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "res = cv2.resize(img1, (0, 0), fx=1, fy=3)\n",
    "plt.imshow(res)"
   ],
   "id": "c8a65d50c2cdd48f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Image thresholding\n",
    "\n",
    "ret, dst = cv2.threshold(src, thresh, maxval, type)\n",
    "\n",
    "- src: The input image. Only single-channel image is allowed, gray image as usual.\n",
    "- dst: The output image.\n",
    "- thresh: The thresholding value.\n",
    "- maxval: When the pixel value is over the thresholding value (or smaller than, depending on type), this value is given.\n",
    "- type: Binary operation type. The following 5 types are included: cv2.THRESH_BINARY, cv2.THRESH_BINARY_INV, cv2.THRESH_TRUNC, cv2.THRESH_TOZERO, cv2.THRESH_TOZERO_INV.\n",
    "- cv2.THRESH_BINARY: maxval for portion exceeding thresh, otherwise 0\n",
    "- cv2.THRESH_BINARY_INV: inverse of THRESH_BINARY\n",
    "- cv2.THRESH_TRUNC: set to thresh for portion exceeding thresh, otherwise no change\n",
    "- cv2.THRESH_TOZERO: no change for portion exceeding thresh, otherwise 0\n",
    "- cv2.THRESH_TOZERO_INV: inverse of THRESH_TOZERO"
   ],
   "id": "7f5e5d6e325fa8f9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "img_gray = cv2.imread('test1.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "ret, thresh1 = cv2.threshold(img_gray, 127, 255, cv2.THRESH_BINARY)\n",
    "ret, thresh2 = cv2.threshold(img_gray, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "ret, thresh3 = cv2.threshold(img_gray, 127, 255, cv2.THRESH_TRUNC)\n",
    "ret, thresh4 = cv2.threshold(img_gray, 127, 255, cv2.THRESH_TOZERO)\n",
    "ret, thresh5 = cv2.threshold(img_gray, 127, 255, cv2.THRESH_TOZERO_INV)\n",
    "\n",
    "titles = ['Original Image', 'BINARY', 'BINARY_INV', 'TRUNC', 'TOZERO', 'TOZERO_INV']\n",
    "images = [img_gray, thresh1, thresh2, thresh3, thresh4, thresh5]\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2, 3, i + 1), plt.imshow(images[i], 'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ],
   "id": "306e63e16a70eb37",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Image smoothing",
   "id": "c6ff5db080809b48"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "img = cv2.imread('test3.jpg')\n",
    "\n",
    "cv2.imshow('image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "16165f677aa56a80",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# average filtration\n",
    "# simple average convolution operation\n",
    "blur = cv2.blur(img, (3, 3))\n",
    "\n",
    "cv2.imshow('blur', blur)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "f6024c24b0c74f16",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# box filtration\n",
    "# Similar to averaging, normalizing is optional.\n",
    "box = cv2.boxFilter(img, -1, (3, 3), normalize=True)\n",
    "\n",
    "cv2.imshow('box', box)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "3aad516a8adbed5f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# box filtration\n",
    "# Similar to averaging, normalizing is optional. Easy to exceed the border.\n",
    "box = cv2.boxFilter(img, -1, (3, 3), normalize=False)\n",
    "\n",
    "cv2.imshow('box', box)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "7a863819dc51039f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Gauss filtration\n",
    "# The value of the convolution kernel within gauss blur meets requirements of Gauss distribution, meaning the middle portion is considered more.\n",
    "\n",
    "gaussian = cv2.GaussianBlur(img, (5, 5), 1)\n",
    "\n",
    "cv2.imshow('gaussian', gaussian)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "3f4657f4faee8950",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# mid-value filtration\n",
    "# equivalent to replacement with mid-value\n",
    "\n",
    "median = cv2.medianBlur(img, 5)\n",
    "\n",
    "cv2.imshow('median', median)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "cd0ba9de4b11db97",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# display all of above\n",
    "\n",
    "res = np.hstack((blur, gaussian, median))\n",
    "cv2.imshow('median vs average', res)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "fec881cf6a1fe8b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Morphology - eroding operation",
   "id": "963e6644caded5f8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "img = cv2.imread('test4.jpg')\n",
    "\n",
    "cv2.imshow('image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "2d0ad6caca6786de",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "kernel = np.ones((5, 5), np.uint8)\n",
    "erosion = cv2.erode(img, kernel, iterations=1)\n",
    "\n",
    "cv2.imshow('erosion', erosion)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "77e5fe72cb328966",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pie = cv2.imread('pie.png')\n",
    "\n",
    "cv2.imshow('pie', pie)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "77645c22d0777e97",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "kernel = np.ones((30, 30), np.uint8)\n",
    "erosion_1 = cv2.erode(pie, kernel, iterations=1)\n",
    "erosion_2 = cv2.erode(pie, kernel, iterations=2)\n",
    "erosion_3 = cv2.erode(pie, kernel, iterations=3)\n",
    "res = np.hstack((erosion_1, erosion_2, erosion_3))\n",
    "cv2.imshow('res', res)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "4072c41c7bf0340a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Morphology - dilating operation",
   "id": "230a37b6a6ff27dc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "img = cv2.imread('test4.jpg')\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "abdb9a82cf9da93f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "kernel = np.ones((3, 3), np.uint8)\n",
    "img_erosion = cv2.erode(img, kernel, iterations=3)\n",
    "\n",
    "cv2.imshow('img_erosion', img_erosion)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "f9e2ef2c407347fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "kernel = np.ones((3, 3), np.uint8)\n",
    "img_dilation = cv2.dilate(img_erosion, kernel, iterations=3)\n",
    "\n",
    "cv2.imshow('img_dilation', img_dilation)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "b824a9d6bbc7e3da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pie = cv2.imread('pie.png')\n",
    "\n",
    "kernel = np.ones((30, 30), np.uint8)\n",
    "dilate_1 = cv2.dilate(pie, kernel, iterations=1)\n",
    "dilate_2 = cv2.dilate(pie, kernel, iterations=2)\n",
    "dilate_3 = cv2.dilate(pie, kernel, iterations=3)\n",
    "res = np.hstack((dilate_1, dilate_2, dilate_3))\n",
    "cv2.imshow('res', res)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "8a53759a4b26f5f2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Opening calculation and closing calculation",
   "id": "c6179a6c5c2dffca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# opening calculation, erode first, then dilate\n",
    "img = cv2.imread('test4.jpg')\n",
    "\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "cv2.imshow('opening', opening)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "88363c6cdcd76618",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# closing calculation, dilate first, then erode\n",
    "img = cv2.imread('test4.jpg')\n",
    "\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "closing = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "cv2.imshow('closing', closing)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "a63c5ed73c4937fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Gradient calculation",
   "id": "babd02b2a931bbe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# gradient = erosion - dilation\n",
    "pie = cv2.imread('pie.png')\n",
    "kernel = np.ones((7, 7), np.uint8)\n",
    "dilate = cv2.dilate(pie, kernel, iterations=5)\n",
    "erosion = cv2.erode(dilate, kernel, iterations=5)\n",
    "\n",
    "res = np.hstack((dilate, erosion))\n",
    "\n",
    "cv2.imshow('res', res)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "e5ba4ea43e28420a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "gradient = cv2.morphologyEx(pie, cv2.MORPH_GRADIENT, kernel)\n",
    "\n",
    "cv2.imshow('gradient', gradient)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "816109d95eae1dae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Tophat vs blackhat\n",
    "\n",
    "- tophat = original input - opening calculation result\n",
    "- blackhat = closed calculation result - original input"
   ],
   "id": "f2c518785e6d5a94"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# tophat\n",
    "img = cv2.imread('test4.jpg')\n",
    "tophat = cv2.morphologyEx(img, cv2.MORPH_TOPHAT, kernel)\n",
    "cv2.imshow('tophat', tophat)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "9ea3300111365d19",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# blackhat\n",
    "img = cv2.imread('test4.jpg')\n",
    "blackhat = cv2.morphologyEx(img, cv2.MORPH_BLACKHAT, kernel)\n",
    "cv2.imshow('blackhat', blackhat)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "642126d167c4d61b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
