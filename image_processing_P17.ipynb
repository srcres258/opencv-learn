{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "%matplotlib inline"
   ],
   "id": "ea6fe7611610c26b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Image gradient - Sobel operator",
   "id": "5b2a1c00076e6df5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "img = cv2.imread('pie.png', cv2.IMREAD_GRAYSCALE)\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "8194020c4d14d003",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "dst = cv2.Sobel(src, ddepth, dx, dy, ksize)\n",
    "\n",
    "- ddepth: depth of image\n",
    "- dx, dy: horizontal and vertical direction\n",
    "- ksize: size of Sobel operator"
   ],
   "id": "dc99b876285d4d6e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def cv_show(img, name):\n",
    "    cv2.imshow(name, img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ],
   "id": "4ab3113025d36353",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=3)\n",
    "\n",
    "cv_show(sobelx, 'sobelx')"
   ],
   "id": "c78072f8551bf63",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Because it's positive from white to black, it's negative from black to white. All negative values will be intercepted to 0, so absolute value should be obtained.",
   "id": "71d97d04d1348106"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=3)\n",
    "sobelx = cv2.convertScaleAbs(sobelx)\n",
    "cv_show(sobelx, 'sobelx')"
   ],
   "id": "901ca650e0398584",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=3)\n",
    "sobely = cv2.convertScaleAbs(sobely)\n",
    "cv_show(sobely, 'sobely')"
   ],
   "id": "42fea4398c3d71ba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Calculate x and y separately, then sum up.",
   "id": "4c950f3ea4fba8a2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sobelxy = cv2.addWeighted(sobelx, 0.5, sobely, 0.5, 0)\n",
    "cv_show(sobelxy, 'sobelxy')"
   ],
   "id": "d714fe6d4df3241c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Directly calculating is not recommended.",
   "id": "c50d22def1210d22"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sobelxy = cv2.Sobel(img, cv2.CV_64F, 1, 1, ksize=3)\n",
    "sobelxy = cv2.convertScaleAbs(sobelxy)\n",
    "cv_show(sobelxy, 'sobelxy')"
   ],
   "id": "76fc199484e90d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "img = cv2.imread('test3.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "cv_show(img, 'img')"
   ],
   "id": "d8b5cb7e2bc77118",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "img = cv2.imread('test3.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=3)\n",
    "sobelx = cv2.convertScaleAbs(sobelx)\n",
    "sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=3)\n",
    "sobely = cv2.convertScaleAbs(sobely)\n",
    "sobelxy = cv2.addWeighted(sobelx, 0.5, sobely, 0.5, 0)\n",
    "cv_show(sobelxy, 'sobelxy')"
   ],
   "id": "b86aa0cbf31ffc7a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "img = cv2.imread('test3.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "sobelxy = cv2.Sobel(img, cv2.CV_64F, 1, 1, ksize=3)\n",
    "sobelxy = cv2.convertScaleAbs(sobelxy)\n",
    "cv_show(sobelxy, 'sobelxy')"
   ],
   "id": "d756451ecd88e903",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Image gradient - Scharr operator",
   "id": "14e4fe7df3e34c89"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Image gradient - Laplacian operator",
   "id": "3bde1f437e2d2c7c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# differences between various operators\n",
    "img = cv2.imread('test3.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=3)\n",
    "sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=3)\n",
    "sobelx = cv2.convertScaleAbs(sobelx)\n",
    "sobely = cv2.convertScaleAbs(sobely)\n",
    "sobelxy = cv2.addWeighted(sobelx, 0.5, sobely, 0.5, 0)\n",
    "\n",
    "scharrx = cv2.Scharr(img, cv2.CV_64F, 1, 0)\n",
    "scharry = cv2.Scharr(img, cv2.CV_64F, 0, 1)\n",
    "scharrx = cv2.convertScaleAbs(scharrx)\n",
    "scharry = cv2.convertScaleAbs(scharry)\n",
    "scharrxy = cv2.addWeighted(scharrx, 0.5, scharry, 0.5, 0)\n",
    "\n",
    "laplacian = cv2.Laplacian(img, cv2.CV_64F)\n",
    "laplacian = cv2.convertScaleAbs(laplacian)\n",
    "\n",
    "res = np.hstack((sobelxy, scharrxy, laplacian))\n",
    "cv_show(res, 'res')"
   ],
   "id": "63c027a33c3f2e31",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Canny border detecting\n",
    "\n",
    "1) Use Gauss filter to smooth the image and filter out the noise.\n",
    "2) Calculate gradient strength and direction of each pixel within the image.\n",
    "3) Use non-maximum suppression, in order to eliminate spurious responses brought by the border detection.\n",
    "4) Use double-threshold detection to ensure real and potential borders.\n",
    "5) Finish up the border detection by restricting isolated weak borders."
   ],
   "id": "fd723d4801d332c0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Gauss filter\n",
    "\n",
    "## 2. Gradient and direction\n",
    "\n",
    "## 3. Non-maximum suppression\n",
    "\n",
    "## 4. Double-threshold detection"
   ],
   "id": "e183459ff4dd21a5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "img = cv2.imread('test1.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "v1 = cv2.Canny(img, 80, 150)\n",
    "v2 = cv2.Canny(img, 50, 100)\n",
    "\n",
    "res = np.hstack((img, v1, v2))\n",
    "cv_show(res, 'res')"
   ],
   "id": "f01fc07215f4d336",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "img = cv2.imread('test3.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "v1 = cv2.Canny(img, 120, 250)\n",
    "v2 = cv2.Canny(img, 50, 100)\n",
    "\n",
    "res = np.hstack((img, v1, v2))\n",
    "cv_show(res, 'res')"
   ],
   "id": "4acdb6eb0e2b9bfb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Image pyramid\n",
    "\n",
    "- Gauss pyramid\n",
    "- Laplace pyramid\n",
    "\n",
    "## Gauss pyramid: down-oriented sampling method (narrowing)\n",
    "\n",
    "## Gauss pyramid: up-oriented sampling method (enlarging)"
   ],
   "id": "1f0c53b016156004"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "img = cv2.imread('test5.jpg')\n",
    "cv_show(img, 'img')\n",
    "print(img.shape)"
   ],
   "id": "b62642cd13a6f247",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "up = cv2.pyrUp(img)\n",
    "cv_show(up, 'up')\n",
    "print(up.shape)"
   ],
   "id": "a654654705ed8466",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "down = cv2.pyrDown(img)\n",
    "cv_show(down, 'down')\n",
    "print(down.shape)"
   ],
   "id": "d53b2d9e04cf74ca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "up2 = cv2.pyrUp(up)\n",
    "cv_show(up2, 'up2')\n",
    "print(up2.shape)"
   ],
   "id": "48f47b89d681eb5f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "up = cv2.pyrUp(img)\n",
    "up_down = cv2.pyrDown(up)\n",
    "cv_show(up_down, 'up_down')"
   ],
   "id": "6cc8e30fd73b7816",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Laplace pyramid",
   "id": "3abd7905e82e7ac9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "down = cv2.pyrDown(img)\n",
    "down_up = cv2.pyrUp(down)\n",
    "l_l = img - down_up\n",
    "cv_show(l_l, 'l_l')"
   ],
   "id": "a867427e086ddb90",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Image contour\n",
    "\n",
    "cv2.findContours(img, mode, method)\n",
    "\n",
    "mode: mode of contour searching\n",
    "- RETR_EXTERNAL: only search for the outer contour\n",
    "- RETR_LIST: search for all contours, and store them into a linked list\n",
    "- RETR_CCOMP: search for all contours, and organise them as two layers: first layer is outer contours of all portions, second layer is borders of null holes.\n",
    "- RETR_TREE: search for all contours, and refactor all layers of nested contours\n",
    "\n",
    "method: method of contour approaching\n",
    "- CHAIN_APPROX_NONE: output the contour in Freeman chain code, and all of other methods output polygons (sequence of vertices)\n",
    "- CHAIN_APPROX_SIMPLE: compress horizontal, vertical and slanted portions, i.e. the function only reserves their destination portions."
   ],
   "id": "98c3cfb3b494e600"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In order to enhance precision, binary-value images are used.",
   "id": "290c5097158487ac"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "img = cv2.imread('test2.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "cv_show(thresh, 'thresh')"
   ],
   "id": "e784eb47aaedc6e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)",
   "id": "b2057fc9b7301d64",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "draw the contours",
   "id": "215d8975ecfb3901"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Pass the image to draw, contours, contour indices, color mode, thickness of stroke\n",
    "# Note that copying is necessary, or the original image will change...\n",
    "draw_img = img.copy()\n",
    "res = cv2.drawContours(draw_img, contours, -1, (0, 0, 255), 2)\n",
    "cv_show(res, 'res')"
   ],
   "id": "525548e201679d6c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "draw_img = img.copy()\n",
    "res = cv2.drawContours(draw_img, contours, 8, (0, 0, 255), 2)\n",
    "cv_show(res, 'res')"
   ],
   "id": "8fcc226ef4a64bcd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Contour features",
   "id": "506b1978acd2799c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "cnt = contours[8]",
   "id": "5ef615974f77b615",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# area\n",
    "cv2.contourArea(cnt)"
   ],
   "id": "567c1b88bb96a5f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# perimeter, True means closed\n",
    "cv2.arcLength(cnt, True)"
   ],
   "id": "8d2f025ff4cbdfde",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Contour approximating",
   "id": "194ab4555e2bb58a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "img = cv2.imread('test4.jpg')\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "cnt = contours[0]\n",
    "\n",
    "draw_img = img.copy()\n",
    "res = cv2.drawContours(draw_img, contours, -1, (0, 0, 255), 2)\n",
    "cv_show(res, 'res')"
   ],
   "id": "59feb4b3ecbf7c1f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "epsilon = 0.01 * cv2.arcLength(cnt, True)\n",
    "approx = cv2.approxPolyDP(cnt, epsilon, True)\n",
    "\n",
    "draw_img = img.copy()\n",
    "res = cv2.drawContours(draw_img, [approx], -1, (0, 0, 255), 2)\n",
    "cv_show(res, 'res')"
   ],
   "id": "74ea1703312ac6d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Border rectangle",
   "id": "872e9ebbd3178139"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "img = cv2.imread('test4.jpg')\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "cnt = contours[0]\n",
    "\n",
    "x, y, w, h = cv2.boundingRect(cnt)\n",
    "img = cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "cv_show(img, 'img')"
   ],
   "id": "ee1db9d99bdc4166",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "area = cv2.contourArea(cnt)\n",
    "x, y, w, h = cv2.boundingRect(cnt)\n",
    "rect_area = w * h\n",
    "extent = float(area) / rect_area\n",
    "print('Area ratio between contour and border rectangle:', extent)"
   ],
   "id": "d32c9ab79fa00865",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Circumscribed circle",
   "id": "9a778ba93e95343c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "(x, y), radius = cv2.minEnclosingCircle(cnt)\n",
    "center = (int(x), int(y))\n",
    "radius = int(radius)\n",
    "img = cv2.circle(img, (int(x), int(y)), radius, (0, 255, 0), 2)\n",
    "cv_show(img, 'img')"
   ],
   "id": "a3a4aa148e31f99f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
